const { openai, config } = require('../config/openai.config');
const { DENTAL_ASSISTANT_PROMPT } = require('../config/systemPrompts');
const { processApiIntegration } = require('./apiIntegration.service');
const { handleQuery } = require('./queryEngine.service');

class AIService {
  /**
   * Send message to GPT and get response (with Query Engine integration)
   * @param {Array} messages - Array of messages in OpenAI format
   * @param {String} systemPrompt - System prompt (optional, uses default if not provided)
   * @param {String} authToken - JWT token for authenticated API calls (optional)
   * @returns {Promise<Object>} - { response: string, queryData: any }
   */
  async sendMessageToGPT(messages, systemPrompt = DENTAL_ASSISTANT_PROMPT, authToken = null) {
    try {
      // Step 1: Get initial response from GPT
      const response = await openai.chat.completions.create({
        model: config.model,
        messages: [
          { role: 'system', content: systemPrompt },
          ...messages
        ],
        temperature: config.temperature,
        max_tokens: config.maxTokens
      });

      const gptResponse = response.choices[0].message.content;
      console.log('ü§ñ GPT Response:', gptResponse);

      // Step 2: Check if GPT wants to query database
      if (this.hasQueryRequest(gptResponse)) {
        console.log('üîç Query request detected, executing Query Engine...');
        
        // Extract query prompt from [QUERY]...[/QUERY] tags
        const queryPrompt = this.extractQueryPrompt(gptResponse);
        console.log('üìù Query Prompt:', queryPrompt);

        // Execute Query Engine
        const queryResult = await handleQuery(queryPrompt);

        if (queryResult.success) {
          console.log(`‚úÖ Query executed successfully: ${queryResult.count} results`);
          
          // Step 3: Send query results back to GPT for natural language response
          const resultsContext = this.formatQueryResultsForGPT(queryResult);
          
          const finalResponse = await openai.chat.completions.create({
            model: config.model,
            messages: [
              { role: 'system', content: systemPrompt },
              ...messages,
              { 
                role: 'system', 
                content: `K·∫æT QU·∫¢ TR·ªä V·∫§N:\n${resultsContext}\n\nH√£y t·ªïng h·ª£p th√¥ng tin tr√™n v√† tr·∫£ l·ªùi ng∆∞·ªùi d√πng m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán. ƒê·ª´ng n√≥i v·ªÅ query hay database.` 
              }
            ],
            temperature: config.temperature,
            max_tokens: config.maxTokens
          });

          return {
            response: finalResponse.choices[0].message.content,
            queryData: queryResult.data,
            queryCount: queryResult.count,
            usedQuery: true,
            query: queryResult.query
          };
        } else {
          console.error('‚ùå Query execution failed:', queryResult.error);
          // Fallback to GPT response without query data
          return {
            response: gptResponse.replace(/\[QUERY\].*?\[\/QUERY\]/g, '').trim() || 'Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p. Vui l√≤ng li√™n h·ªá hotline ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£! üìû',
            queryData: null,
            usedQuery: false,
            error: queryResult.error
          };
        }
      } else {
        // No query needed, return direct GPT response
        console.log('‚ÑπÔ∏è  No query needed, returning GPT response');
        return {
          response: gptResponse,
          queryData: null,
          usedQuery: false
        };
      }

    } catch (error) {
      console.error('‚ùå OpenAI API Error:', error);
      throw new Error('Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau.');
    }
  }

  /**
   * Check if GPT response contains query request
   * @param {String} response - GPT response
   * @returns {Boolean}
   */
  hasQueryRequest(response) {
    return response.includes('[QUERY]') && response.includes('[/QUERY]');
  }

  /**
   * Extract query prompt from [QUERY]...[/QUERY] tags
   * @param {String} response - GPT response
   * @returns {String}
   */
  extractQueryPrompt(response) {
    const match = response.match(/\[QUERY\](.*?)\[\/QUERY\]/s);
    return match ? match[1].trim() : '';
  }

  /**
   * Format query results for GPT to generate natural language response
   * @param {Object} queryResult - Result from Query Engine
   * @returns {String}
   */
  formatQueryResultsForGPT(queryResult) {
    if (!queryResult.success || !queryResult.data || queryResult.data.length === 0) {
      return 'Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o trong database.';
    }

    let formatted = `T√¨m th·∫•y ${queryResult.count} k·∫øt qu·∫£ t·ª´ collection "${queryResult.query.collection}":\n\n`;
    
    // Limit to first 5 results for context
    const limitedData = queryResult.data.slice(0, 5);
    
    limitedData.forEach((item, index) => {
      formatted += `${index + 1}. ${JSON.stringify(item, null, 2)}\n\n`;
    });

    if (queryResult.count > 5) {
      formatted += `... v√† ${queryResult.count - 5} k·∫øt qu·∫£ kh√°c.`;
    }

    return formatted;
  }

  /**
   * Send message to GPT (simplified version without API integration)
   * @param {Array} messages - Array of messages
   * @param {String} systemPrompt - System prompt
   * @returns {Promise<String>} - GPT response text only
   */
  async sendSimpleMessage(messages, systemPrompt = DENTAL_ASSISTANT_PROMPT) {
    try {
      const response = await openai.chat.completions.create({
        model: config.model,
        messages: [
          { role: 'system', content: systemPrompt },
          ...messages
        ],
        temperature: config.temperature,
        max_tokens: config.maxTokens
      });

      return response.choices[0].message.content;
    } catch (error) {
      console.error('‚ùå OpenAI API Error:', error);
      throw new Error('Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau.');
    }
  }

  /**
   * Format conversation history for OpenAI
   * @param {Array} messages - Messages from database
   * @returns {Array} - Formatted messages for OpenAI
   */
  formatMessagesForGPT(messages) {
    return messages
      .filter(msg => msg.role !== 'system')
      .map(msg => ({
        role: msg.role,
        content: msg.content
      }));
  }

  /**
   * Check if message is dental-related
   * @param {String} message - User message
   * @returns {Boolean}
   */
  isDentalRelated(message) {
    const dentalKeywords = [
      // Ti·∫øng Vi·ªát - C∆° b·∫£n
      'rƒÉng', 'nha khoa', 'kh√°m', 'b√°c sƒ©', 'nha sƒ©', 'd·ªãch v·ª•', 
      'ƒë·∫∑t l·ªãch', 'ƒë·∫∑t h·∫πn', 'gi√°', 'chi ph√≠', 'ph√≠', 'ti·ªÅn',
      
      // D·ªãch v·ª•
      't·∫©y tr·∫Øng', 'ni·ªÅng', 'ch·ªânh nha', 'b·ªçc rƒÉng', 'c·∫•y gh√©p',
      'nh·ªï', 'tr√°m', 'implant', 's·ª©', 'veneer', 'l·∫•y cao',
      
      // Tri·ªáu ch·ª©ng & B·ªánh l√Ω
      'n∆∞·ªõu', 'vi√™m', 'ƒëau', 'nh·ª©c', 's√¢u', 'm·∫•t', 'h·ªèng', 
      'ch·∫£y m√°u', 's∆∞ng', 'm·ªß', '·ªë v√†ng', 'm·∫£ng b√°m', 'kh·ªõp c·∫Øn',
      'th∆∞a', 'm√≥m', 'h√¥', 'l·ªách', 'lung lay', 'y·∫øu',
      
      // Ph√≤ng kh√°m & Th∆∞∆°ng hi·ªáu
      'ph√≤ng kh√°m', 'smilecare', 'smile care', 'nha khoa smile',
      
      // English
      'appointment', 'teeth', 'tooth', 'dental', 'dentist', 
      'orthodontic', 'braces', 'whitening', 'cavity', 'gum'
    ];

    const lowerMessage = message.toLowerCase();
    return dentalKeywords.some(keyword => lowerMessage.includes(keyword));
  }
}

module.exports = new AIService();
